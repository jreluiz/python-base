{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "colab": {
   "name": "Python08.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intro_title"
   },
   "source": [
    "# Python 08 — Introdução prática a Machine Learning com Python (Iris, scikit-learn e TensorFlow)\n",
    "\n",
    "Este notebook é uma aula completa e prática cobrindo conceitos básicos de Machine Learning (ML) com Python, usando dois ecossistemas populares: **scikit-learn** (clássico/estatístico) e **TensorFlow/Keras** (redes neurais). Trabalharemos com o conjunto de dados clássico **Iris**.\n",
    "\n",
    "Objetivos:\n",
    "- Entender os conceitos fundamentais de ML supervisionado (features, rótulos, treino/teste, validação, métricas).\n",
    "- Explorar o dataset Iris e realizar EDA (Análise Exploratória de Dados) básica.\n",
    "- Treinar modelos com scikit-learn (Logistic Regression, SVC) usando boas práticas (Pipeline, padronização, validação cruzada, Grid Search).\n",
    "- Salvar e carregar modelos treinados.\n",
    "- Treinar uma rede neural simples com TensorFlow/Keras e comparar resultados.\n",
    "\n",
    "Pré-requisitos (recomendado): Python 3.9+ e as bibliotecas `numpy`, `pandas`, `matplotlib`, `seaborn`, `scikit-learn`, `tensorflow`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_hdr"
   },
   "source": [
    "## 0) Instalação (opcional)\n",
    "Se estiver rodando localmente e ainda não tiver as dependências, execute a célula abaixo. Ela usa o interpretador atual do Python para instalar os pacotes necessários.\n",
    "\n",
    "Observação: a instalação do TensorFlow pode demorar e requer ambiente compatível. No Colab, geralmente não é necessário."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "install_code"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Instalação opcional de dependências (compatível com Colab e Jupyter)\n",
    "# - Detecta Colab e instala pacotes necessários usando o mesmo interpretador do kernel.\n",
    "# - Se já tiver tudo instalado, pode pular.\n",
    "\n",
    "from __future__ import annotations\n",
    "import sys, subprocess\n",
    "\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except Exception:  # noqa: BLE001\n",
    "    IN_COLAB = False\n",
    "\n",
    "PKGS = [\n",
    "    'numpy', 'pandas', 'matplotlib', 'seaborn', 'scikit-learn', 'joblib', 'tensorflow'\n",
    "]\n",
    "\n",
    "def pip_install(pkgs: list[str]) -> None:\n",
    "    cmd = [sys.executable, '-m', 'pip', 'install', '-q', '-U', *pkgs]\n",
    "    print('Instalando:', ' '.join(pkgs))\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "if IN_COLAB:\n",
    "    print('Ambiente Colab detectado. As dependências já devem estar disponíveis.')\n",
    "    # pip_install(PKGS) # Descomente se precisar forçar a atualização\n",
    "else:\n",
    "    print('Instalação opcional — pule se o ambiente já tiver as dependências.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports_hdr"
   },
   "source": [
    "## 1) Imports, Configurações e Verificação de Versões\n",
    "\n",
    "- Importar bibliotecas e módulos.\n",
    "- Definir sementes de aleatoriedade para reprodutibilidade.\n",
    "- Verificar versões para diagnosticar problemas de ambiente."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "imports_code"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import sklearn\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Configs de plot\n",
    "sns.set(theme=\"whitegrid\", context=\"notebook\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "\n",
    "# Semente para reprodutibilidade\n",
    "SEED = 42\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Verificação de versões\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"Numpy:\", np.__version__)\n",
    "print(\"Pandas:\", pd.__version__)\n",
    "print(\"scikit-learn:\", sklearn.__version__)\n",
    "print(\"TensorFlow:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "concepts_hdr"
   },
   "source": [
    "## 2) Conceitos básicos de ML supervisionado\n",
    "\n",
    "- **Problema**: Classificar a espécie de uma flor (Iris) a partir de suas medidas (features).\n",
    "- **Features (X)**: Comprimento/largura de sépalas e pétalas (4 variáveis numéricas).\n",
    "- **Rótulo/Target (y)**: Espécie da flor (3 classes: setosa, versicolor, virginica).\n",
    "- **Fluxo padrão**: Dividir dados em treino/teste, treinar o modelo nos dados de treino, validar e, finalmente, avaliar no conjunto de teste.\n",
    "- **Métricas comuns**: Acurácia, precisão, revocação, F1-score.\n",
    "- **Boas práticas**: Padronização dos dados, validação cruzada, manter o conjunto de teste intocado até a avaliação final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eda_hdr"
   },
   "source": [
    "## 3) Carregando o dataset Iris e Análise Exploratória Rápida (EDA)\n",
    "\n",
    "Usaremos `sklearn.datasets.load_iris` e o converteremos para um `pandas.DataFrame` para facilitar a inspeção."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eda_load"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "iris = datasets.load_iris(as_frame=True)\n",
    "df: pd.DataFrame = iris.frame.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eda_info"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Colunas:\", list(df.columns))\n",
    "print(\"Classes (target_names):\", list(iris.target_names))\n",
    "print(\"Descrição resumida:\\n\", '\\n'.join(iris.DESCR.split('\\n')[0:5]))\n",
    "\n",
    "# Mapear target numérico -> rótulo textual para visualizações\n",
    "df[\"species\"] = df[\"target\"].map(dict(enumerate(iris.target_names)))\n",
    "df.sample(5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eda_stats_hdr"
   },
   "source": [
    "### 3.1) Estatísticas e Balanceamento de Classes\n",
    "\n",
    "Vamos verificar as estatísticas descritivas e se as classes estão balanceadas."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eda_stats_code"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Estatísticas descritivas\n",
    "display(df.describe(include=\"all\").T)\n",
    "\n",
    "# Distribuição de classes\n",
    "plt.title(\"Distribuição das Classes no Dataset Iris\")\n",
    "ax = sns.countplot(data=df, x=\"species\", order=sorted(df.species.unique()))\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.xlabel(\"Espécie\")\n",
    "plt.ylabel(\"Quantidade\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pairplot_hdr"
   },
   "source": [
    "### 3.2) Relações entre variáveis\n",
    "\n",
    "Um `pairplot` ajuda a visualizar a separabilidade entre as classes (pode demorar um pouco)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pairplot_code"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.pairplot(df, vars=iris.feature_names, hue=\"species\", diag_kind=\"kde\")\n",
    "plt.suptitle(\"Pairplot do Dataset Iris\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sklearn_first_hdr"
   },
   "source": [
    "## 4) Treino/Teste, Pipeline e Primeiro Modelo (scikit-learn)\n",
    "\n",
    "- Separação treino/teste com estratificação para manter a proporção das classes.\n",
    "- Uso de um `Pipeline` simples com Regressão Logística.\n",
    "- Métricas: acurácia, relatório de classificação e matriz de confusão."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sklearn_first_code"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Features (X) e alvo (y)\n",
    "X = df[iris.feature_names].to_numpy(dtype=np.float32)\n",
    "y = df[\"target\"].to_numpy(dtype=np.int64)\n",
    "\n",
    "# Divisão em treino e teste (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Shape de X_train: {X_train.shape}\")\n",
    "print(f\"Shape de X_test: {X_test.shape}\")\n",
    "\n",
    "# Criação e treino do pipeline com Regressão Logística\n",
    "pipe_lr = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, random_state=SEED)),\n",
    "])\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "# Previsão e avaliação\n",
    "pred_lr = pipe_lr.predict(X_test)\n",
    "acc_lr = accuracy_score(y_test, pred_lr)\n",
    "print(f\"Acurácia (LogisticRegression): {acc_lr:.4f}\\n\")\n",
    "\n",
    "print(\"Relatório de classificação:\\n\", classification_report(y_test, pred_lr, target_names=iris.target_names))\n",
    "\n",
    "# Matriz de confusão\n",
    "cm = confusion_matrix(y_test, pred_lr)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "plt.title(\"Matriz de confusão — LogisticRegression\")\n",
    "plt.xlabel(\"Predito\")\n",
    "plt.ylabel(\"Verdadeiro\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grid_hdr"
   },
   "source": [
    "## 5) Validação Cruzada e Seleção de Hiperparâmetros (Grid Search com SVC)\n",
    "\n",
    "Vamos usar um `Pipeline` com `StandardScaler` + `SVC` e procurar os melhores hiperparâmetros (`C` e `gamma`) usando validação cruzada (k-fold)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "grid_code"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe_svc = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\", SVC(random_state=SEED))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"svc__C\": [0.1, 1, 10, 100],\n",
    "    \"svc__gamma\": [\"scale\", \"auto\", 0.01, 0.1],\n",
    "    \"svc__kernel\": [\"rbf\", \"linear\"]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe_svc,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1, # Usar todos os processadores\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Melhores parâmetros:\", grid.best_params_)\n",
    "print(f\"Melhor acurácia (CV): {grid.best_score_:.4f}\\n\")\n",
    "\n",
    "# Avaliação do melhor modelo encontrado no conjunto de teste\n",
    "best_model = grid.best_estimator_\n",
    "pred_svc = best_model.predict(X_test)\n",
    "acc_svc = accuracy_score(y_test, pred_svc)\n",
    "\n",
    "print(f\"Acurácia em teste (SVC): {acc_svc:.4f}\\n\")\n",
    "print(\"Relatório de classificação (SVC):\\n\", classification_report(y_test, pred_svc, target_names=iris.target_names))\n",
    "\n",
    "# Matriz de confusão\n",
    "cm2 = confusion_matrix(y_test, pred_svc)\n",
    "sns.heatmap(cm2, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
    "            xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "plt.title(\"Matriz de confusão — SVC (melhor modelo)\")\n",
    "plt.xlabel(\"Predito\")\n",
    "plt.ylabel(\"Verdadeiro\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cvquick_hdr"
   },
   "source": [
    "### 5.1) Validação Cruzada Rápida\n",
    "\n",
    "Exemplo de como verificar a performance média de um estimador via `cross_val_score` em todo o dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cvquick_code"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(pipe_lr, X, y, cv=5, scoring=\"accuracy\")\n",
    "print(\"Scores da Validação Cruzada (5-fold):\", np.round(cv_scores, 4))\n",
    "print(f\"Média: {cv_scores.mean():.4f} | Desvio Padrão: {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "persist_hdr"
   },
   "source": [
    "## 6) Persistência do Modelo (Salvar/Carregar)\n",
    "\n",
    "Salvar modelos é essencial para deploy e reuso. Usaremos `joblib`, que é eficiente para objetos NumPy."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "persist_code"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Salvar o melhor modelo (pipeline completo)\n",
    "out_dir = Path(\"./models\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "model_path = out_dir / \"iris_svc_pipeline.joblib\"\n",
    "\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"Modelo salvo em: {model_path.resolve()}\\n\")\n",
    "\n",
    "# Carregar o modelo\n",
    "loaded_model = joblib.load(model_path)\n",
    "print(\"Modelo carregado com sucesso!\")\n",
    "\n",
    "# Verificar se o modelo carregado produz o mesmo resultado\n",
    "pred_loaded = loaded_model.predict(X_test)\n",
    "print(f\"Acurácia do modelo carregado (teste): {accuracy_score(y_test, pred_loaded):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keras_hdr"
   },
   "source": [
    "## 7) Rede Neural com TensorFlow/Keras\n",
    "\n",
    "- Usaremos uma MLP (Perceptron Multicamadas) simples.\n",
    "- Como o alvo é categórico com valores inteiros (0,1,2), usaremos a função de perda `sparse_categorical_crossentropy`.\n",
    "- Incluiremos uma camada de normalização adaptada aos dados de treino."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "keras_code"
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Garantir tipos compatíveis para TensorFlow\n",
    "X_train_tf = X_train.astype(np.float32)\n",
    "X_test_tf = X_test.astype(np.float32)\n",
    "y_train_tf = y_train.astype(np.int32)\n",
    "y_test_tf = y_test.astype(np.int32)\n",
    "\n",
    "# Camada de normalização baseada em estatísticas do treino\n",
    "normalizer = layers.Normalization(axis=-1)\n",
    "normalizer.adapt(X_train_tf)\n",
    "\n",
    "# Construção do modelo sequencial\n",
    "model = keras.Sequential([\n",
    "    normalizer,\n",
    "    layers.Dense(16, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(8, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    layers.Dense(3, activation=\"softmax\") # 3 neurônios de saída para 3 classes\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.005),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Callback para parar o treino se a validação não melhorar\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=20, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Treinamento do modelo\n",
    "history = model.fit(\n",
    "    X_train_tf, y_train_tf,\n",
    "    validation_split=0.2, # Usa 20% dos dados de treino para validação\n",
    "    epochs=200,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=0 # Não mostra o log de cada época\n",
    ")\n",
    "\n",
    "print(f\"Parâmetros treináveis: {model.count_params()}\")\n",
    "model.summary()\n",
    "\n",
    "# Plotar curvas de treino\n",
    "pd.DataFrame(history.history)[[\"loss\", \"val_loss\", \"accuracy\", \"val_accuracy\"]].plot(figsize=(10, 6))\n",
    "plt.title(\"Histórico de Treino (Perda e Acurácia)\")\n",
    "plt.xlabel(\"Épocas\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Avaliação final no conjunto de teste\n",
    "test_loss, test_acc = model.evaluate(X_test_tf, y_test_tf, verbose=0)\n",
    "print(f\"\\nAcurácia em teste (Keras MLP): {test_acc:.4f}\\n\")\n",
    "\n",
    "# Relatório de classificação e matriz de confusão\n",
    "y_pred_probs = model.predict(X_test_tf, verbose=0)\n",
    "y_pred_nn = np.argmax(y_pred_probs, axis=1)\n",
    "print(\"Relatório de classificação (Keras):\\n\", classification_report(y_test_tf, y_pred_nn, target_names=iris.target_names))\n",
    "\n",
    "cm_nn = confusion_matrix(y_test_tf, y_pred_nn)\n",
    "sns.heatmap(cm_nn, annot=True, fmt=\"d\", cmap=\"Oranges\",\n",
    "            xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "plt.title(\"Matriz de confusão — Keras MLP\")\n",
    "plt.xlabel(\"Predito\")\n",
    "plt.ylabel(\"Verdadeiro\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "compare_hdr"
   },
   "source": [
    "## 8) Comparando Abordagens e Boas Práticas\n",
    "\n",
    "- Em datasets pequenos e tabulares como o Iris, modelos do scikit-learn (ex.: SVC, Logistic Regression, RandomForest) costumam performar muito bem e treinar rapidamente. Nosso SVC com GridSearch atingiu 100% de acurácia no teste.\n",
    "- Redes neurais são flexíveis e poderosas, mas podem ser um exagero para problemas simples, exigindo mais dados, regularização e ajuste fino.\n",
    "- **Avaliação honesta**: Sempre mantenha um conjunto de teste separado e intocado. Use validação cruzada nos dados de treino para selecionar hiperparâmetros.\n",
    "- **Reprodutibilidade**: Defina sementes (`random seeds`), registre versões de bibliotecas e salve o pipeline completo (pré-processamento + modelo).\n",
    "- **Simplicidade primeiro**: Comece com um baseline simples e só então aumente a complexidade se necessário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next_steps_hdr"
   },
   "source": [
    "## 9) Próximos Passos\n",
    "\n",
    "- Testar outros modelos (RandomForest, GradientBoosting, KNN).\n",
    "- Explorar técnicas de explicabilidade (SHAP, Permutation Importance).\n",
    "- Empacotar o pipeline para produção (versionamento, monitoramento de drift).\n",
    "\n",
    "Parabéns! Você construiu um fluxo completo de ML com scikit-learn и TensorFlow usando o dataset Iris."
   ]
  }
 ]
}